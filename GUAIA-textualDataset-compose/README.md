# Datasets para Detec√ß√£o / Verifica√ß√£o de Fake News (foco em PT-BR)

Este README lista conjuntos de dados relevantes para **fake news** e **fact-checking**, dando prioridade aos recursos em **portugu√™s do Brasil (PT-BR)**. Inclui notas sobre escopo (fake/real vs. vi√©s, rumor/stance, etc.) e links oficiais.

---

## üìä Tabela resumida (prioridade PT-BR)

| Dataset | Idioma | Tarefa / Classes | Link principal | Observa√ß√µes |
|---|---|---|---|---|
| **Fake.Br Corpus** | PT-BR | **Fake vs Real** | https://github.com/roneysco/Fake.br-Corpus | Baseline cl√°ssico PT-BR, not√≠cias rotuladas. |
| **FactChecks.br (Anonymous)** | PT-BR | Metadados de checagens | https://huggingface.co/datasets/fake-news-Anonymous/FactChecksbr | Links e registros de *fact-checks* brasileiros (n√£o bin√°rio direto). |
| **MuMiN-PT** | PT-BR (subset) | Rumor / Stance / Social | https://huggingface.co/datasets/ju-resplande/MuMiN-PT | Subconjunto PT de corpus multil√≠ngue focado em rumores/redes sociais. |
| **FakeRecogna** | PT-BR | Detec√ß√£o (ver repo p/ r√≥tulos) | https://github.com/Gabriel-Lino-Garcia/FakeRecogna | Recurso PT-BR; verificar esquema e r√≥tulos no reposit√≥rio. |
| **Central de Fatos (paper)** | PT-BR | Refer√™ncia / Mapeamento | https://sol.sbc.org.br/index.php/dsw/article/view/17421 | Artigo; discute acervos e fluxos de checagem no Brasil. |
| **Survey CEUR-WS** | PT-BR | Revis√£o (survey) | https://ceur-ws.org/Vol-3199/paper1.pdf | Vis√£o geral acad√™mica sobre detec√ß√£o/checagem; √∫til para referenciar. |
| **FactNews** | PT-BR/Mult | **N√£o** √© fake/real: ‚àí1=Quotes, 0=Factual, 1=Biased | http://zenodo.org/records/10794023 | √ötil p/ vi√©s/factualidade; **n√£o** ground truth fake/real. |
| **FactCheckTweet (tweets)** | PT-BR | Metadados de checagens em tweets | (Google Drive ID / gdown) | Tweets com links a checagens (*article_url*). Exige normaliza√ß√£o; nem sempre h√° r√≥tulo direto FAKE/REAL. |
| **FKTC** | PT-BR | Coleta / ferramentas | https://github.com/GoloMarcos/FKTC | Acervo/cole√ß√£o; conferir documenta√ß√£o. |

### Outros (principalmente EN ou multil√≠ngue)

| Dataset | Idioma | Tarefa / Classes | Link principal | Observa√ß√µes |
|---|---|---|---|---|
| **LIAR** | EN | Multiclasse (e.g., *pants-on-fire*, *false*, ‚Ä¶) | https://huggingface.co/datasets/ucsbnlp/liar/blob/main/liar.py | Curto, pol√≠tico, n√£o PT-BR. |
| **PolitiFact (Kaggle)** | EN | Fact-checking (metadados/texto) | https://www.kaggle.com/datasets/rmisra/politifact-fact-check-dataset/data | Bom p/ benchmarks EN. |
| **FakeNewsNet** | EN | Multimodal (texto + engajamento) | https://github.com/KaiDMML/FakeNewsNet | Largamente em ingl√™s (BuzzFeed/PolitiFact). |
| **FakeNewsSet** | ‚Äî | ‚Äî | https://huggingface.co/datasets/fake-news-Anonymous/FakeNewsSet/blob/main/FakeNewsSet.py | Defini√ß√£o dispon√≠vel; dados completos n√£o totalmente p√∫blicos. |
| **FCN** | Misto | Verificar escopo/tema | https://zenodo.org/records/5236636 | Pode ser tem√°tico (ex.: COVID); confirmar idioma. |

> **Nota sobre FactNews:** classes **‚àí1 ‚Üí ‚ÄúQuotes‚Äù**, **0 ‚Üí ‚ÄúFactual‚Äù**, **1 ‚Üí ‚ÄúBiased‚Äù**. **N√£o** usar como substituto direto de *fake vs real*.

---

## üáßüá∑ PT-BR (detalhado)

### Fake.Br Corpus
- **Link:** https://github.com/roneysco/Fake.br-Corpus  
- **Tarefa:** classifica√ß√£o **fake vs real** em PT-BR.  
- **Formato:** textos de not√≠cias com r√≥tulos bin√°rios.  
- **Uso t√≠pico:** baseline PT-BR; √≥timo para few/zero-shot ou supervisionado.  
- **Dica:** padronize colunas (`idx`, `text`, `label`) e salve em Parquet/CSV p/ pipelines.

### FactChecks.br (acervo Anonymous)
- **Link:** https://huggingface.co/datasets/fake-news-Anonymous/FactChecksbr  
- **Tipo:** **metadados** de checagens brasileiras (t√≠tulos, URLs, etc.).  
- **Uso:** √≥timo para coletar **evid√™ncias** e rastros de checagem; n√£o √© bin√°rio direto.

### MuMiN-PT (subset)
- **Links:** https://huggingface.co/datasets/ju-resplande/MuMiN-PT ¬∑ Paper: https://dl.acm.org/doi/abs/10.1145/3477495.3531744  
- **Tarefa:** rumor verification / stance / intera√ß√µes sociais.  
- **Observa√ß√£o:** n√£o √© ‚Äúnot√≠cia longa ‚Üí fake/real‚Äù cl√°ssico; foco em rumor/redes sociais.

### FakeRecogna
- **Link:** https://github.com/Gabriel-Lino-Garcia/FakeRecogna  
- **Observa√ß√£o:** conjunto + ferramentas para PT-BR; conferir no reposit√≥rio o esquema de r√≥tulos/parti√ß√µes.

### Central de Fatos (paper)
- **Link:** https://sol.sbc.org.br/index.php/dsw/article/view/17421  
- **Uso:** refer√™ncia/survey sobre acervos e o ecossistema brasileiro de checagem.

### **Survey CEUR-WS (Panorama PT-BR)**
- **Link:** https://ceur-ws.org/Vol-3199/paper1.pdf  
- **Conte√∫do:** vis√£o geral de t√©cnicas e desafios em PT-BR; bom para contextualizar trabalhos e citar em revis√µes relacionadas.

### FactNews (aten√ß√£o ao r√≥tulo)
- **Links:** Zenodo: http://zenodo.org/records/10794023 ¬∑ Paper: https://arxiv.org/pdf/2301.11850  
- **Classes:** ‚àí1 *Quotes*, 0 *Factual*, 1 *Biased*.  
- **Uso:** an√°lise de vi√©s/factualidade; **n√£o** usar como fake/real.

### **FactCheckTweet (tweets com checagens)**
- **Aquisi√ß√£o:** dispon√≠vel via **Google Drive ID** (ex.: `gdown --id <ID>`).  
- **Esquema t√≠pico:** `tweet_id`, `article_url`, `label` (quando presente).  
- **Observa√ß√µes pr√°ticas:**  
  - Muitos registros trazem **apenas o link da checagem**; nem sempre h√° r√≥tulo FAKE/REAL diretamente.  
  - Alguns **links quebrados** exigem *crawling* ou *resolvers* de URL.  
  - Requer **normaliza√ß√£o** para alinhar com tarefas bin√°rias (ex.: inferir r√≥tulos a partir do veredito do artigo de checagem).  

### FKTC
- **Link:** https://github.com/GoloMarcos/FKTC  
- **Observa√ß√£o:** acervo/coleta; ver docs para formato e disponibilidade.

---

## üåê Multil√≠ngue / Ingl√™s (para transfer√™ncia ou compara√ß√£o)

### LIAR
- **Links:** HF: https://huggingface.co/datasets/ucsbnlp/liar/blob/main/liar.py ¬∑ Kaggle (var.): https://www.kaggle.com/datasets/doanquanvietnamca/liar-dataset?select=valid.tsv  
- **Idioma:** ingl√™s.  
- **Tarefa:** *fact-checking* multiclasse (r√≥tulos granulares).  
- **Uso:** √∫til para *transfer learning* e compara√ß√£o com PT-BR.

### PolitiFact (Kaggle)
- **Link:** https://www.kaggle.com/datasets/rmisra/politifact-fact-check-dataset/data  
- **Observa√ß√£o:** checagens em EN; bom para benchmarks.

### FakeNewsNet
- **Link:** https://github.com/KaiDMML/FakeNewsNet  
- **Observa√ß√£o:** multimodal (texto + engajamento), majoritariamente EN.

### FakeNewsSet
- **Links:** ACM: https://dl.acm.org/doi/abs/10.1145/3428658.3430965 ¬∑ HF def.: https://huggingface.co/datasets/fake-news-Anonymous/FakeNewsSet/blob/main/FakeNewsSet.py  
- **Observa√ß√£o:** defini√ß√£o publicada; dataset completo n√£o totalmente p√∫blico.

### FCN
- **Link:** https://zenodo.org/records/5236636  
- **Observa√ß√£o:** verificar idioma e dom√≠nio (pode ser tem√°tico).

---

## üß∞ Exemplos r√°pidos de uso

### Carregar no Hugging Face
```python
from datasets import load_dataset

# FactChecks.br (metadados de fact-checks brasileiros)
ds_fc = load_dataset("fake-news-XXX/FactChecksbr")

# MuMiN-PT (subset em portugu√™s)
ds_mumin = load_dataset("ju-resplande/MuMiN-PT")
```

### Converter corpus local para Parquet
```python
import pandas as pd

df = pd.DataFrame([
    {"idx":"fake_0001","text":"Exemplo de not√≠cia...", "label":"FAKE"},
    {"idx":"true_0001","text":"Outra not√≠cia...", "label":"REAL"},
])
df.to_parquet("meu_dataset.parquet", index=False)
```

---

## ‚úÖ Escolha r√°pida por objetivo

- **Fake vs Real (PT-BR):** **Fake.Br** (principal), **FakeRecogna** (ver labels), e subsets PT do **MuMiN-PT** (se sua tarefa for rumor/stance).  
- **Evid√™ncias e hist√≥rico de checagens (PT-BR):** **FactChecks.br**, **Central de Fatos**, **FKTC**, **FactCheckTweet**.  
- **Vi√©s/Factualidade (n√£o fake/real):** **FactNews**.  
- **Transfer√™ncia / compara√ß√£o (EN):** **LIAR**, **PolitiFact**, **FakeNewsNet**.

> Dica: ao unificar corpora, normalize colunas para `idx`, `text`, `label` (com `label ‚àà {FAKE, REAL}` quando aplic√°vel) e centralize tudo em Parquet para pipelines reprodut√≠veis.


Novo dataset: 
FACTCK.BR https://github.com/jghm-f/FACTCK.BR/blob/master/FACTCKBR.tsv
Esses tem as classes: ['falso',
 'distorcido',
 'impreciso',
 'exagerado',
 'insustent√°vel',
 'verdadeiro',
 'outros',
 'Falso',
 'Subestimado',
 'Verdadeiro',
 'Exagerado',
 'Imposs√≠vel provar',
 'Discut√≠vel',
 'Sem contexto',
 nan,
 'Distorcido',
 'De olho',
 'Verdadeiro, mas',
 'Ainda √© cedo para dizer'] - No artigo, sometne considere Falso e Verdadeiro
FAKETRUE.BR https://github.com/roneysco/Fake.br-Corpus